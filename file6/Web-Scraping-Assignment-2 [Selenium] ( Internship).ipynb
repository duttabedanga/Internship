{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f935740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f82755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (4.12.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.4)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\riki\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e84b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "#This task will be done in following steps:\n",
    "#1. First get the webpage https://www.shine.com/\n",
    "#2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "#3. Then click the search button.\n",
    "#4. Then scrape the data for the first 10 jobs results you get.\n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the shine page on automated chrome browser (#1. First get the webpage https://www.shine.com/)\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3655a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning designation and location as required in the Q (#2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.)\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "designation.send_keys('Data Analyst ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b7e52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f55b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Then click the search button.\n",
    "search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9a8256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list for store \n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experienced_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9fee02d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Hiring For Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Clinical Data Analyst',\n",
       " 'Mobility Data Analyst - IN/MKR',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Engineer II, Amazon WFM Tech Enterprise Data',\n",
       " 'Data Analyst - Java/Python',\n",
       " 'Business Data Analyst, GlowRoad']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping job title from the given page (#4. Then scrape the data for the first 10 jobs results you get)\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title [0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28818263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore\\n+8',\n",
       " 'Bangalore\\n+8',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+4',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+13',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping job location from the given page \n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]'):\n",
    "    job_location.append(i.text)\n",
    "job_location  [0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36a3f8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['harjai computers private limited',\n",
       " 'harjai computers private limited',\n",
       " 'true caller',\n",
       " 'quiscon biotech',\n",
       " 'bosch group',\n",
       " 'true caller',\n",
       " 'rama technical consultants',\n",
       " 'amazon',\n",
       " 'boyen haddin consulting and technol...',\n",
       " 'amazon']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping company name from the given page\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]'):\n",
    "    company_name.append(i.text)\n",
    "company_name  [0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86fe388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 to 2 Yrs',\n",
       " '2 to 5 Yrs',\n",
       " '3 to 5 Yrs',\n",
       " '0 to 2 Yrs',\n",
       " '4 to 6 Yrs',\n",
       " '5 to 7 Yrs',\n",
       " '11 to 21 Yrs',\n",
       " '3 to 5 Yrs',\n",
       " '3 to 6 Yrs',\n",
       " '1 to 3 Yrs']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping experienced required from the given page\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]'):\n",
    "    experienced_required.append(i.text)\n",
    "experienced_required [0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe91c7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>harjai computers private limited</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>harjai computers private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>true caller</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobility Data Analyst - IN/MKR</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>true caller</td>\n",
       "      <td>5 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>rama technical consultants</td>\n",
       "      <td>11 to 21 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer II, Amazon WFM Tech Enterprise Data</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>amazon</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst, GlowRoad</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>amazon</td>\n",
       "      <td>1 to 3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0                                Senior Data Analyst   Bangalore\\n+8   \n",
       "1                            Hiring For Data Analyst   Bangalore\\n+8   \n",
       "2                                       Data Analyst       Bangalore   \n",
       "3                              Clinical Data Analyst   Bangalore\\n+4   \n",
       "4                     Mobility Data Analyst - IN/MKR       Bangalore   \n",
       "5                                Senior Data Analyst       Bangalore   \n",
       "6                                       Data Analyst  Bangalore\\n+13   \n",
       "7  Data Engineer II, Amazon WFM Tech Enterprise Data       Bangalore   \n",
       "8                         Data Analyst - Java/Python       Bangalore   \n",
       "9                    Business Data Analyst, GlowRoad       Bangalore   \n",
       "\n",
       "                             Company Name    Experience  \n",
       "0        harjai computers private limited    0 to 2 Yrs  \n",
       "1        harjai computers private limited    2 to 5 Yrs  \n",
       "2                             true caller    3 to 5 Yrs  \n",
       "3                         quiscon biotech    0 to 2 Yrs  \n",
       "4                             bosch group    4 to 6 Yrs  \n",
       "5                             true caller    5 to 7 Yrs  \n",
       "6              rama technical consultants  11 to 21 Yrs  \n",
       "7                                  amazon    3 to 5 Yrs  \n",
       "8  boyen haddin consulting and technol...    3 to 6 Yrs  \n",
       "9                                  amazon    1 to 3 Yrs  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Title':job_title[0:10] , 'Location':job_location[0:10] , 'Company Name':company_name[0:10] , 'Experience':experienced_required[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "55ca4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "#This task will be done in following steps:\n",
    "#1. First get the webpage https://www.shine.com/\n",
    "#2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "#3. Then click the search button.\n",
    "#4. Then scrape the data for the first 10 jobs results you get.\n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the shine page on automated chrome browser (#1. First get the webpage https://www.shine.com/)\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "938ef3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning designation and location as required in the Q (#2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.)\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control \")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "73a7fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Then click the search button.\n",
    "search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8da47713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>the fashion cosmo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR. DATA SCIENTIST</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>te connectivity india pvt ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist- ML Engineer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>sap india pvt ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Hiring Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>inmobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist, AWS</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job Title    Job Location  \\\n",
       "0                                Data Scientist       Bangalore   \n",
       "1                            SR. DATA SCIENTIST       Bangalore   \n",
       "2            Senior Data Scientist- ML Engineer       Bangalore   \n",
       "3  Data Scientist Hiring Fresher and Experience  Bangalore\\n+17   \n",
       "4                            Data Scientist III       Bangalore   \n",
       "5                                Data Scientist   Bangalore\\n+6   \n",
       "6                    Senior Data Scientist, AWS       Bangalore   \n",
       "7                    Data Scientist Recruitment  Bangalore\\n+17   \n",
       "8                     Hiring For Data Scientist  Bangalore\\n+17   \n",
       "9                     Hiring For Data Scientist  Bangalore\\n+17   \n",
       "\n",
       "                    Company Name  \n",
       "0              the fashion cosmo  \n",
       "1  te connectivity india pvt ltd  \n",
       "2              sap india pvt ltd  \n",
       "3       kavya staffing solutions  \n",
       "4                         inmobi  \n",
       "5                quiscon biotech  \n",
       "6                         amazon  \n",
       "7       kavya staffing solutions  \n",
       "8       kavya staffing solutions  \n",
       "9       kavya staffing solutions  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Empty list for store \n",
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "\n",
    "\n",
    "#Scraping job title from the given page (#4. Then scrape the data for the first 10 jobs results you get)\n",
    "for i in driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]'):\n",
    "    title.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "#Scraping job location from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]'):\n",
    "    location.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "#Scraping company name from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]'):\n",
    "    company.append(i.text)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Job Title':title[0:10] , 'Job Location':location[0:10] , 'Company Name':company[0:10] })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f1e85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "#You have to use the location and salary filter.\n",
    "#You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "#You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "#The task will be done as shown in the below steps:\n",
    "#1. first get the web page https://www.shine.com/\n",
    "#2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "#3. Then click the search button.\n",
    "#4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "#5. Then scrape the data for the first 10 jobs results you get.\n",
    "#6. Finally create a dataframe of the scraped data.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the shine page on automated chrome browser (#1. First get the webpage https://www.shine.com/)\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6f84840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning designation and location as required in the Q (#2. Enter “Data Analyst” in “Job title, Skills” field )\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control \")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "507f23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Then click the search button.\n",
    "search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2251b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.applying the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "#Locate the location filter button and click it\n",
    "\n",
    "location_filter=driver.find_element(By.CLASS_NAME,\"filter_filter_lists_items__wlFfo\")\n",
    "location_filter.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5545373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search Delhi in search bar \n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[1]/input\")\n",
    "location.send_keys('Delhi')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36620d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting on Delhi option\n",
    "delhi_click=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[2]/span/label\")\n",
    "delhi_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d87a7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate the salary filter button and click it\n",
    "salary_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/ul/li[3] \")\n",
    "salary_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81ffc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting on 3-5L option on salary filter\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13d796c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the show result button\n",
    "show_result=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "show_result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8cc558a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST DELHI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA SCIENTIST DELHI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA SCIENTIST DELHI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>corporate steps..</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Delhi\\n+8</td>\n",
       "      <td>harjai computers private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Delhi\\n+8</td>\n",
       "      <td>harjai computers private limited</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job Title Job Location  \\\n",
       "0                                Data Scientist    Delhi\\n+6   \n",
       "1                          DATA SCIENTIST DELHI        Delhi   \n",
       "2                                Data Scientist    Delhi\\n+6   \n",
       "3                          DATA SCIENTIST DELHI        Delhi   \n",
       "4                          DATA SCIENTIST DELHI        Delhi   \n",
       "5                          Senior Data Engineer    Delhi\\n+6   \n",
       "6                       Hiring For Data Analyst    Delhi\\n+8   \n",
       "7                           Senior Data Analyst    Delhi\\n+8   \n",
       "8  for _GCP Data Engineer/Lead/Architect- Delhi        Delhi   \n",
       "9  for _GCP Data Engineer/Lead/Architect- Delhi        Delhi   \n",
       "\n",
       "                       Company Name experience required  \n",
       "0                   quiscon biotech           0 to 1 Yr  \n",
       "1               skyleaf consultants          3 to 6 Yrs  \n",
       "2                   quiscon biotech          0 to 3 Yrs  \n",
       "3               skyleaf consultants          3 to 6 Yrs  \n",
       "4               skyleaf consultants          3 to 6 Yrs  \n",
       "5                 corporate steps..          2 to 4 Yrs  \n",
       "6  harjai computers private limited          2 to 5 Yrs  \n",
       "7  harjai computers private limited          0 to 2 Yrs  \n",
       "8             nina s hr consultancy          2 to 3 Yrs  \n",
       "9             nina s hr consultancy          2 to 3 Yrs  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Then scrape the data for the first 10 jobs results you get.\n",
    "#Empty list for store \n",
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]\n",
    "\n",
    "\n",
    "#Scraping job title from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]'):\n",
    "    title.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "#Scraping job location from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]'):\n",
    "    location.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "#Scraping company name from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]'):\n",
    "    company.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping experience required from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]'):\n",
    "    experience.append(i.text)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Job Title':title[0:10] , 'Job Location':location[0:10] , 'Company Name':company[0:10],'experience required':experience[:10] })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f59c21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#. Brand\n",
    "#. Product Description\n",
    "#. Price\n",
    "#The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "#To scrape the data you have to go through following steps:\n",
    "#1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "#2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "#3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "#4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "#5. Now scrape data from this page as usual\n",
    "#6. Repeat this until you get data for 100sunglasses.\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening Flipkart webpage on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9292cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning “sunglasses” in the search field\n",
    "search=driver.find_element(By.CLASS_NAME,\"Pke_EE \")\n",
    "search.send_keys('sunglasses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ebd65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "click=driver.find_element(By.CLASS_NAME,\"_2iLD__\")\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21e8b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now scrape the datas like Brand, Product Description, Price for the 100sunglasses (After scraping data from the first page, go to the “Next” Button at the bottom other page)\n",
    "\n",
    "#Empty list for store \n",
    "Brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "#from 3 pages so that we can scrape atleast 100 datas\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "#Scraping Barand name \n",
    "for page in range(start,end):\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        Brand.append(i.text)\n",
    "    \n",
    "    \n",
    "    #Scraping Product Description \n",
    "    for i in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "        Description.append(i.text)\n",
    "    \n",
    "    #Scraping Price\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        Price.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') #to scrape data from next page\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c64096e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 118, 120)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brand),len(Description),len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b3a247b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (59)</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (58)</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Crazywinks</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (60)</td>\n",
       "      <td>₹749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>UV Protection Butterfly Sunglasses (60)</td>\n",
       "      <td>₹1,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹1,520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Mirrored Aviator Sunglasses (58)</td>\n",
       "      <td>₹388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description   Price\n",
       "0    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)    ₹849\n",
       "1    VINCENT CHASE             UV Protection Wayfarer Sunglasses (59)    ₹549\n",
       "2         Fastrack             UV Protection Wayfarer Sunglasses (58)    ₹649\n",
       "3         Fastrack              UV Protection Aviator Sunglasses (58)    ₹799\n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹499\n",
       "..             ...                                                ...     ...\n",
       "95      Crazywinks   Polarized, UV Protection Aviator Sunglasses (60)    ₹749\n",
       "96     john jacobs            UV Protection Butterfly Sunglasses (60)  ₹1,799\n",
       "97     Eyewearlabs   UV Protection Wrap-around Sunglasses (Free Size)  ₹1,520\n",
       "98          PIRASO                   Mirrored Aviator Sunglasses (58)    ₹388\n",
       "99  ROZZETTA CRAFT  Polarized, UV Protection Retro Square Sunglass...    ₹490\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Brand Name':Brand[0:100] , 'Product Description':Description[:100] , 'Price':Price[0:100] })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4df0a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\n",
    "\n",
    "#As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "#1. Rating\n",
    "#2. Review summary\n",
    "#3. Full review\n",
    "#4. You have to scrape this data for first 100reviews.\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening Flipkart webpage on automated chrome browser \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\")\n",
    "\n",
    "#[SHOWING THIS MESSAGE : Unfortunately the page you are looking for has been moved or deleted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbedd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa7c5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "#You have to scrape 3 attributes of each sneaker:\n",
    "#. Brand\n",
    "#. Product Description\n",
    "#. Price\n",
    "#As shown in the image, you have to scrape the above attributes.\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening Flipkart webpage on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7b2f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning “sneakers” in the search field\n",
    "search=driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "#search.submit()......we can use this also to click the search button\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef642e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "click=driver.find_element(By.CLASS_NAME,\"_2iLD__\")\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "332d105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now scrape the datas like Brand, Product Description, Price for the sneakers (After scraping data from the first page, go to the “Next” Button at the bottom other page)\n",
    "\n",
    "#Empty list for store \n",
    "Brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "#from 3 pages so that we can scrape atleast 100 datas\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    #Scraping Barand name \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        Brand.append(i.text)\n",
    "    \n",
    "    \n",
    "    #Scraping Product Description \n",
    "    for i in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'): #DOUBT: Only 'flipkart assured' description is been taken \n",
    "        Description.append(i.text)\n",
    "    \n",
    "    #Scraping Price\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        Price.append(i.text)\n",
    "    \n",
    "    \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') #to scrape data from next page\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2f7d2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 112, 120)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brand),len(Description),len(Price) # to check the length of each column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78a64b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asian</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>CLARKIN Sneakers For Men</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>asian</td>\n",
       "      <td>Stylish &amp; Trending Lifestyle Casual Sneakers F...</td>\n",
       "      <td>₹622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Carnival-01 Mens Casual,Loafers Chunky Sneaker...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Free Kicks</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>asian</td>\n",
       "      <td>asian Thunder-01 White Color Change Sneakers,C...</td>\n",
       "      <td>₹646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Name                                Product Description   Price\n",
       "0       Layasa                                   Sneakers For Men    ₹279\n",
       "1       Layasa                                   Sneakers For Men    ₹499\n",
       "2        asian                                   Sneakers For Men    ₹822\n",
       "3     Nobelite                                   Sneakers For Men    ₹279\n",
       "4         aadi                           CLARKIN Sneakers For Men    ₹279\n",
       "..         ...                                                ...     ...\n",
       "95       asian  Stylish & Trending Lifestyle Casual Sneakers F...    ₹622\n",
       "96      Layasa  Carnival-01 Mens Casual,Loafers Chunky Sneaker...    ₹499\n",
       "97      Layasa                                   Sneakers For Men    ₹549\n",
       "98  Free Kicks                                   Sneakers For Men  ₹1,400\n",
       "99       asian  asian Thunder-01 White Color Change Sneakers,C...    ₹646\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Brand Name':Brand[0:100] , 'Product Description':Description[:100] , 'Price':Price[0:100] })\n",
    "df\n",
    "\n",
    "# DOUBT: i feel its showing randomly as its not matching with the page's shoes sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14288f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2feca29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "#After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "#. Title\n",
    "#. Ratings\n",
    "#. Price\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening amazon webpage on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e1b0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning “Laptop” in the search field\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")  #need to use XPATH instead of CLASS_NAME where no option appears when click on search field\n",
    "search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6669e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "search.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "932d8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set CPU Type filter to “Intel Core i7” button and click it\n",
    "CPU_type=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/span[10]/li/span/a/span\")\n",
    "CPU_type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d179ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now scrape the datas like Title, Ratings, Price for the first 10 laptops data.\n",
    "\n",
    "#Empty list for store \n",
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "    \n",
    "#Scraping Title \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]'):\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Ratings \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-size-base puis-bold-weight-text\"]'):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping Price \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-price\"]'):\n",
    "    Price.append(i.text)\n",
    "    \n",
    "len(Title),len(Ratings),len(Price) # to check the length of each column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d60cea47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title Name</th>\n",
       "      <th>Product Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>₹68,829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>₹1,44,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>₹66,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>₹64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 5430 Laptop, Intel Core i7-1360P...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>₹86,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>₹68,829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>₹1,15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS Creator Series Vivobook 14X OLED (2023), ...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>₹80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>₹1,03,625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title Name Product Rating      Price\n",
       "0  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...            4.2    ₹68,829\n",
       "1  Acer Predator Helios Neo 16 Gaming Laptop 13th...            4.0  ₹1,44,990\n",
       "2  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...            4.3    ₹66,990\n",
       "3  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...            4.0    ₹64,990\n",
       "4  Dell Inspiron 5430 Laptop, Intel Core i7-1360P...            3.3    ₹86,490\n",
       "5  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...            4.2    ₹68,829\n",
       "6  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...            4.4  ₹1,15,990\n",
       "7  ASUS Creator Series Vivobook 14X OLED (2023), ...            4.6    ₹89,990\n",
       "8  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...            4.1    ₹80,990\n",
       "9  ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...            4.0  ₹1,03,625"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe of the scraped first 10 laptops datas (3 attributes for each laptop)\n",
    "\n",
    "df=pd.DataFrame({'Title Name':Title[0:10] , 'Product Rating':Ratings[:10] , 'Price':Price[:10] })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad18fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e346fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "#The above task will be done in following steps:\n",
    "#1. First get the webpagehttps://www.azquotes.com/\n",
    "#2. Click on Top Quotes\n",
    "#3. Than scrap a) Quote b) Author c) Type Of Quotes\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening Quotes webpage on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b44d2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on 'Top Quotes'  {#need to use XPATH instead of CLASS_NAME where no option appears when click on search field or anything}\n",
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c19fb0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now scrape a) Quote b) Author c) Type Of Quotes , data for Top 1000 Quotes of All Time\n",
    "\n",
    "#Empty list for store \n",
    "Quote=[]\n",
    "Author=[]\n",
    "Type=[]\n",
    "\n",
    "\n",
    "#from all 10 pages so that we can scrape all 1000 Quotes\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    #Scraping Quote  \n",
    "    for i in driver.find_elements(By.XPATH,'//a[@class=\"title\"]'):\n",
    "        Quote.append(i.text)\n",
    "    \n",
    "    \n",
    "    #Scraping Author name \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"author\"]'):  \n",
    "        Author.append(i.text)\n",
    "    \n",
    "    #Scraping Type Of Quotes\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"tags\"]'):\n",
    "        Type.append(i.text)\n",
    "    \n",
    "    \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"active\"]') #to scrape data from next page\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "\n",
    "len(Quote),len(Author),len(Type) # to check the length of each column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2897cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Type Of Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote           Author Name  \\\n",
       "0    The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                 ...                   ...   \n",
       "995     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "996  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "997  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "998  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "999    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                               Type Of Quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995                    Music, Sports, Hunting  \n",
       "996             Trust, Encouraging, Uplifting  \n",
       "997              Inspirational, Funny, Change  \n",
       "998                      Success, God, Mother  \n",
       "999       Inspirational, Motivational, Change  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create a dataframe of the scraped all 10 pages datas of all 1000 Quotes\n",
    "\n",
    "df=pd.DataFrame({'Quote':Quote , 'Author Name':Author , 'Type Of Quotes':Type })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81672c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bb6d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "#This task will be done in following steps:\n",
    "#1. First get the webpagehttps://www.jagranjosh.com/\n",
    "#2. Then You have to click on the GK option\n",
    "#3. Then click on the List of all Prime Ministers of India\n",
    "#4. Then scrap the mentioned data and make the DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening webpage on automated chrome browser (#1. First get the webpagehttps://www.jagranjosh.com/)\n",
    "\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d65f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on 'GK' option {#need to use XPATH instead of CLASS_NAME where no option appears when click on search field or anything}\n",
    "#(2. Then You have to click on the GK option)\n",
    "GK=driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div/div/div[3]/ul/li[3]/a\")\n",
    "GK.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68d4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the List of all Prime Ministers of India {#need to use XPATH instead of CLASS_NAME where no option appears when click on search field or anything}\n",
    "#(3. Then click on the List of all Prime Ministers of India)\n",
    "prime_minister=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "prime_minister.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cd105e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: Unable to locate an element with the xpath expression ............. because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '.............' is not a valid XPath expression.\n  (Session info: chrome=117.0.5938.92); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6006C7892+54818]\n\t(No symbol) [0x00007FF600636AC2]\n\t(No symbol) [0x00007FF6004EDA3B]\n\t(No symbol) [0x00007FF6004F246D]\n\t(No symbol) [0x00007FF6004F3F5F]\n\t(No symbol) [0x00007FF6004F4050]\n\t(No symbol) [0x00007FF60052E184]\n\t(No symbol) [0x00007FF60052E67C]\n\t(No symbol) [0x00007FF600569657]\n\t(No symbol) [0x00007FF60054EAEF]\n\t(No symbol) [0x00007FF6005675A2]\n\t(No symbol) [0x00007FF60054E883]\n\t(No symbol) [0x00007FF600523691]\n\t(No symbol) [0x00007FF6005248D4]\n\tGetHandleVerifier [0x00007FF600A2B992+3610402]\n\tGetHandleVerifier [0x00007FF600A81860+3962352]\n\tGetHandleVerifier [0x00007FF600A79D4F+3930847]\n\tGetHandleVerifier [0x00007FF600763646+693206]\n\t(No symbol) [0x00007FF600641628]\n\t(No symbol) [0x00007FF60063D934]\n\t(No symbol) [0x00007FF60063DA62]\n\t(No symbol) [0x00007FF60062E113]\n\tBaseThreadInitThunk [0x00007FFF22887344+20]\n\tRtlUserThreadStart [0x00007FFF23CA26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7332\\3754296617.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#Scraping Name Of former Prime Ministers of India\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.............'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#(NOT ABLE TO FIND THE CLASSS NAME TO SELECT ALL FROM THE COLUMN)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mName\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m: Message: invalid selector: Unable to locate an element with the xpath expression ............. because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '.............' is not a valid XPath expression.\n  (Session info: chrome=117.0.5938.92); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6006C7892+54818]\n\t(No symbol) [0x00007FF600636AC2]\n\t(No symbol) [0x00007FF6004EDA3B]\n\t(No symbol) [0x00007FF6004F246D]\n\t(No symbol) [0x00007FF6004F3F5F]\n\t(No symbol) [0x00007FF6004F4050]\n\t(No symbol) [0x00007FF60052E184]\n\t(No symbol) [0x00007FF60052E67C]\n\t(No symbol) [0x00007FF600569657]\n\t(No symbol) [0x00007FF60054EAEF]\n\t(No symbol) [0x00007FF6005675A2]\n\t(No symbol) [0x00007FF60054E883]\n\t(No symbol) [0x00007FF600523691]\n\t(No symbol) [0x00007FF6005248D4]\n\tGetHandleVerifier [0x00007FF600A2B992+3610402]\n\tGetHandleVerifier [0x00007FF600A81860+3962352]\n\tGetHandleVerifier [0x00007FF600A79D4F+3930847]\n\tGetHandleVerifier [0x00007FF600763646+693206]\n\t(No symbol) [0x00007FF600641628]\n\t(No symbol) [0x00007FF60063D934]\n\t(No symbol) [0x00007FF60063DA62]\n\t(No symbol) [0x00007FF60062E113]\n\tBaseThreadInitThunk [0x00007FFF22887344+20]\n\tRtlUserThreadStart [0x00007FFF23CA26B1+33]\n"
     ]
    }
   ],
   "source": [
    "#4. Then scrap the mentioned data ( Name, Born-Dead, Term of office, Remarks) of former Prime Ministers of India and make the DataFrame.\n",
    "\n",
    "\n",
    "#Empty list for store \n",
    "Name=[]\n",
    "Life=[]\n",
    "Office=[]\n",
    "Remarks=[]\n",
    "\n",
    "\n",
    "\n",
    "#Scraping Name Of former Prime Ministers of India\n",
    "for i in driver.find_elements(By.XPATH,'.............'): #(NOT ABLE TO FIND THE CLASSS NAME TO SELECT ALL FROM THE COLUMN)\n",
    "    Name.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Born-Dead Of former Prime Ministers of India\n",
    "for i in driver.find_elements(By.XPATH,'//td[@style=\"width: 105px; height: 80px;\"]'):  #(NOT ABLE TO FIND THE CLASSS NAME TO SELECT ALL FROM THE COLUMN)\n",
    "    Life.append(i.text)\n",
    "   \n",
    " \n",
    "#Scraping Term of office Of former Prime Ministers of India\n",
    "for i in driver.find_elements(By.XPATH,'..........'):  #(NOT ABLE TO FIND THE CLASSS NAME TO SELECT ALL FROM THE COLUMN)\n",
    "    Office.append(i.text)\n",
    " \n",
    "\n",
    " \n",
    "#Scraping Remarks Of former Prime Ministers of India   \n",
    "for i in driver.find_elements(By.XPATH,'.............'): #(NOT ABLE TO FIND THE CLASSS NAME TO SELECT ALL FROM THE COLUMN)\n",
    "    Remarks.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "len(Name),len(Life),len(Office),len(Remarks) # to check the length of each column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e64299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a dataframe of the all former Prime Ministers of India\n",
    "\n",
    "df=pd.DataFrame({'Name':Name , 'Born-Dead':Life , 'Term of office':Office,'Remarks':Remarks })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236a1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c266e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fae7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "#This task will be done in following steps:\n",
    "#1. First get the webpage https://www.motor1.com/\n",
    "#2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "#3. Then click on 50 most expensive cars in the world..\n",
    "#4. Then scrap the mentioned data and make the dataframe.\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening webpage on automated chrome browser (#1. First get the webpage https://www.motor1.com/)\n",
    "\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0862762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on search bar to type in the search bar ’50 most expensive cars’ {#need to use XPATH instead of CLASS_NAME where no option appears when click on search field or anything}\n",
    "#(2.Then You have to type in the search bar ’50 most expensive cars’)\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[10]/div[2]/div/div/div[3]/div/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ffd5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning “50 most expensive cars” in the search field\n",
    "cars=driver.find_element(By.XPATH,\"/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input\")  #need to use XPATH instead of CLASS_NAME where no option appears when click on search field\n",
    "cars.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edf46777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "cars.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95bd6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Then select on 50 most expensive cars in the world..\n",
    "\n",
    "select=driver.find_element(By.XPATH,\"/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a\")\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c1c9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: Unable to locate an element with the xpath expression <p><strong>Price: $1.5 Million</strong></p> because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '<p><strong>Price: $1.5 Million</strong></p>' is not a valid XPath expression.\n  (Session info: chrome=117.0.5938.92); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6006C7892+54818]\n\t(No symbol) [0x00007FF600636AC2]\n\t(No symbol) [0x00007FF6004EDA3B]\n\t(No symbol) [0x00007FF6004F246D]\n\t(No symbol) [0x00007FF6004F3F5F]\n\t(No symbol) [0x00007FF6004F4050]\n\t(No symbol) [0x00007FF60052E184]\n\t(No symbol) [0x00007FF60052E67C]\n\t(No symbol) [0x00007FF600569657]\n\t(No symbol) [0x00007FF60054EAEF]\n\t(No symbol) [0x00007FF6005675A2]\n\t(No symbol) [0x00007FF60054E883]\n\t(No symbol) [0x00007FF600523691]\n\t(No symbol) [0x00007FF6005248D4]\n\tGetHandleVerifier [0x00007FF600A2B992+3610402]\n\tGetHandleVerifier [0x00007FF600A81860+3962352]\n\tGetHandleVerifier [0x00007FF600A79D4F+3930847]\n\tGetHandleVerifier [0x00007FF600763646+693206]\n\t(No symbol) [0x00007FF600641628]\n\t(No symbol) [0x00007FF60063D934]\n\t(No symbol) [0x00007FF60063DA62]\n\t(No symbol) [0x00007FF60062E113]\n\tBaseThreadInitThunk [0x00007FFF22887344+20]\n\tRtlUserThreadStart [0x00007FFF23CA26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7332\\432189040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#Scraping Car Price Of 50 Most expensive cars in the world\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'<p><strong>Price: $1.5 Million</strong></p>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mPrice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m: Message: invalid selector: Unable to locate an element with the xpath expression <p><strong>Price: $1.5 Million</strong></p> because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '<p><strong>Price: $1.5 Million</strong></p>' is not a valid XPath expression.\n  (Session info: chrome=117.0.5938.92); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6006C7892+54818]\n\t(No symbol) [0x00007FF600636AC2]\n\t(No symbol) [0x00007FF6004EDA3B]\n\t(No symbol) [0x00007FF6004F246D]\n\t(No symbol) [0x00007FF6004F3F5F]\n\t(No symbol) [0x00007FF6004F4050]\n\t(No symbol) [0x00007FF60052E184]\n\t(No symbol) [0x00007FF60052E67C]\n\t(No symbol) [0x00007FF600569657]\n\t(No symbol) [0x00007FF60054EAEF]\n\t(No symbol) [0x00007FF6005675A2]\n\t(No symbol) [0x00007FF60054E883]\n\t(No symbol) [0x00007FF600523691]\n\t(No symbol) [0x00007FF6005248D4]\n\tGetHandleVerifier [0x00007FF600A2B992+3610402]\n\tGetHandleVerifier [0x00007FF600A81860+3962352]\n\tGetHandleVerifier [0x00007FF600A79D4F+3930847]\n\tGetHandleVerifier [0x00007FF600763646+693206]\n\t(No symbol) [0x00007FF600641628]\n\t(No symbol) [0x00007FF60063D934]\n\t(No symbol) [0x00007FF60063DA62]\n\t(No symbol) [0x00007FF60062E113]\n\tBaseThreadInitThunk [0x00007FFF22887344+20]\n\tRtlUserThreadStart [0x00007FFF23CA26B1+33]\n"
     ]
    }
   ],
   "source": [
    "#4. Then scrap the mentioned data ( Car name and Price) of 50 Most expensive cars in the world and make the DataFrame.\n",
    "\n",
    "\n",
    "#Empty list for store \n",
    "Car=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "\n",
    "#Scraping Car Name Of 50 Most expensive cars in the world\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]'): \n",
    "    Car.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Car Price Of 50 Most expensive cars in the world\n",
    "for i in driver.find_elements(By.XPATH,'........'):       #(NOT ABLE TO FIND THE CLASSS NAME TO SELECT ALL FROM THE COLUMN)\n",
    "    Price.append(i.text)\n",
    "   \n",
    " \n",
    "    \n",
    "    \n",
    "len(Car),len(Price) # to check the length of each column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c98b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a dataframe of the all 50 Most expensive cars in the world\n",
    "\n",
    "df=pd.DataFrame({'Car Name':Car , 'Car Price':Price })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee8ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
