{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d28d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.1.Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "#A) Rank\n",
    "#B) Name\n",
    "#C) Artist\n",
    "#D) Upload date\n",
    "#E) Views\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "# .strip(): This is a Python string method that removes leading and trailing whitespaces (spaces, tabs, and newlines) from a string. It doesn't affect spaces within the string.\n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser ( Open wikipedia website)\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1aab268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty lists for storing data\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_Date = []\n",
    "Views = []\n",
    "\n",
    "# Find the table with the Top 30 most-viewed YouTube videos details \n",
    "tables = driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]')\n",
    "\n",
    "# Ensure that at least one table is found\n",
    "if tables:\n",
    "    # Assuming the first table contains the data\n",
    "    table = tables[0]\n",
    "\n",
    "    # Loop through the rows of the table to extract data\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        # Check if the number of columns is as expected\n",
    "        if len(columns) >= 5:\n",
    "            rank = columns[0].text\n",
    "            name = columns[1].text\n",
    "            artist = columns[2].text\n",
    "            upload_date = columns[4].text\n",
    "            views = columns[3].text\n",
    "\n",
    "            # Append data to respective lists\n",
    "            Rank.append(rank)\n",
    "            Name.append(name)\n",
    "            Artist.append(artist)\n",
    "            Upload_Date.append(upload_date)\n",
    "            Views.append(views)\n",
    "else:\n",
    "    print(\"No tables found on the page.\")\n",
    "\n",
    "# Print the lengths of lists \n",
    "len(Rank),len(Name),len(Upload_Date),len(Views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b8bd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views in Billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[44]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[47]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[52]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[53]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                                      \"Sorry\"[44]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.                                 \"Dark Horse\"[47]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                             \"Girls Like You\"[52]   \n",
       "28  29.                      \"Shree Hanuman Chalisa\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                          Passenger      July 25, 2012   \n",
       "26                                        Alan Walker   December 3, 2015   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "   Views in Billions  \n",
       "0              13.48  \n",
       "1               8.28  \n",
       "2               6.82  \n",
       "3               6.45  \n",
       "4               6.11  \n",
       "5               6.05  \n",
       "6               5.62  \n",
       "7               5.52  \n",
       "8               5.05  \n",
       "9               4.99  \n",
       "10              4.92  \n",
       "11              4.56  \n",
       "12              4.46  \n",
       "13              4.09  \n",
       "14              3.95  \n",
       "15              3.89  \n",
       "16              3.89  \n",
       "17              3.80  \n",
       "18              3.75  \n",
       "19              3.72  \n",
       "20              3.71  \n",
       "21              3.67  \n",
       "22              3.60  \n",
       "23              3.58  \n",
       "24              3.56  \n",
       "25              3.53  \n",
       "26              3.53  \n",
       "27              3.50  \n",
       "28              3.48  \n",
       "29              3.48  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank , ' Name':Name , 'Artist':Artist , 'Upload Date':Upload_Date, 'Views in Billions':Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafceb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8ef1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "#Url = https://www.bcci.tv/.\n",
    "#You need to find following details:\n",
    "#A) Series\n",
    "#B) Place\n",
    "#C) Date\n",
    "#D) Time\n",
    "# Note: - From bcci.tv home page you have reach to the international fixture page through code.\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser ( Open bcci.tv website)\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Then click the close ad.\n",
    "close=driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]')\n",
    "close.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f016bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the Fixtures & Results.\n",
    "Fixtures=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[1]/ul/div[1]/a[2]')\n",
    "Fixtures.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955b5216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 211, 211, 211)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty lists for storing data\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n",
    "\n",
    "\n",
    "#Scraping Series from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-card-middle__inner d-flex justify-content-between\"]'):\n",
    "    Series.append(i.text.replace('\\n','   '))\n",
    "\n",
    "    \n",
    "#Scraping Place from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "    Place.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Scraping Date from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "    Date.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "#Scraping Time from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Print the lengths of lists \n",
    "len(Series),len(Place),len(Date),len(Time)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db221eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India   Bangladesh</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>19 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India   New Zealand</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>22 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India   England</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...</td>\n",
       "      <td>29 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India   Sri Lanka</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>2 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India   South Africa</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>5 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>India   173/8   20.0 overs   Sri Lanka   174/4...</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>6 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>India   181/7   20.0 overs   Pakistan   182/5 ...</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>4 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>India A   571/6 d   143.0 overs   New Zealand ...</td>\n",
       "      <td>M.Chinnaswamy Stadium, Bangalore</td>\n",
       "      <td>1 SEPTEMBER, 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>India   192/2   20.0 overs   Hong Kong   152/5...</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>31 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>India   148/5   19.4 overs   Pakistan   147   ...</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>28 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Series  \\\n",
       "0                                   India   Bangladesh   \n",
       "1                                  India   New Zealand   \n",
       "2                                      India   England   \n",
       "3                                    India   Sri Lanka   \n",
       "4                                 India   South Africa   \n",
       "..                                                 ...   \n",
       "206  India   173/8   20.0 overs   Sri Lanka   174/4...   \n",
       "207  India   181/7   20.0 overs   Pakistan   182/5 ...   \n",
       "208  India A   571/6 d   143.0 overs   New Zealand ...   \n",
       "209  India   192/2   20.0 overs   Hong Kong   152/5...   \n",
       "210  India   148/5   19.4 overs   Pakistan   147   ...   \n",
       "\n",
       "                                                 Place               Date  \\\n",
       "0        Maharashtra Cricket Association Stadium, Pune   19 OCTOBER, 2023   \n",
       "1    Himachal Pradesh Cricket Association Stadium, ...   22 OCTOBER, 2023   \n",
       "2    Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...   29 OCTOBER, 2023   \n",
       "3                             Wankhede Stadium, Mumbai   2 NOVEMBER, 2023   \n",
       "4                                Eden Gardens, Kolkata   5 NOVEMBER, 2023   \n",
       "..                                                 ...                ...   \n",
       "206         Dubai International Cricket Stadium, Dubai  6 SEPTEMBER, 2022   \n",
       "207         Dubai International Cricket Stadium, Dubai  4 SEPTEMBER, 2022   \n",
       "208                   M.Chinnaswamy Stadium, Bangalore  1 SEPTEMBER, 2022   \n",
       "209         Dubai International Cricket Stadium, Dubai    31 AUGUST, 2022   \n",
       "210         Dubai International Cricket Stadium, Dubai    28 AUGUST, 2022   \n",
       "\n",
       "            Time  \n",
       "0    2:00 PM IST  \n",
       "1    2:00 PM IST  \n",
       "2    2:00 PM IST  \n",
       "3    2:00 PM IST  \n",
       "4    2:00 PM IST  \n",
       "..           ...  \n",
       "206  7:30 PM IST  \n",
       "207  7:30 PM IST  \n",
       "208  9:30 AM IST  \n",
       "209  7:30 PM IST  \n",
       "210  7:30 PM IST  \n",
       "\n",
       "[211 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Series':Series , ' Place':Place , 'Date':Date , 'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bae53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea96488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "#Url = http://statisticstimes.com/\n",
    "#You have to find following details: A) Rank\n",
    "#B) State\n",
    "#C) GSDP(18-19)- at current prices\n",
    "#D) GSDP(19-20)- at current prices\n",
    "#E) Share(18-19)\n",
    "#F) GDP($ billion)\n",
    "#Note: - From statisticstimes home page you have to reach to economy page through code.\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser ( Open State-wise GDP  website)\n",
    "\n",
    "driver.get('http://statisticstimes.com/')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Then click the economy option\n",
    "Select=driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]')\n",
    "Select.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Then click the India option in economy\n",
    "india=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "india.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b77405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Then click the 'GDP of India states' option in economy\n",
    "india=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953d2de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34, 34, 34, 34, 34)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty lists for storing data\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP_1 = []\n",
    "GSDP_2 = []\n",
    "Share = []\n",
    "GDP = []\n",
    "\n",
    "# Find the table with the Top 30 most-viewed YouTube videos details \n",
    "tables = driver.find_elements(By.XPATH, '//div[@class=\"dataTables_wrapper\"]')\n",
    "\n",
    "# Ensure that at least one table is found\n",
    "if tables:\n",
    "    # Assuming the first table contains the data\n",
    "    table = tables[0]\n",
    "\n",
    "    # Loop through the rows of the table to extract data\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        # Check if the number of columns is as expected\n",
    "        if len(columns) >= 5:\n",
    "            rank = columns[0].text\n",
    "            state = columns[1].text\n",
    "            gsdp_1 = columns[2].text\n",
    "            gsdp_2 = columns[3].text\n",
    "            share = columns[4].text\n",
    "            gdp = columns[5].text\n",
    "\n",
    "            # Append data to respective lists\n",
    "            Rank.append(rank)\n",
    "            State.append(state)\n",
    "            GSDP_1.append(gsdp_1)\n",
    "            GSDP_2.append(gsdp_2)\n",
    "            Share.append(share)\n",
    "            GDP.append(gdp)\n",
    "else:\n",
    "    print(\"No tables found on the page.\")\n",
    "\n",
    "# Print the lengths of lists \n",
    "len(Rank),len(State),len(GSDP_1),len(GSDP_2),len(Share),len(GDP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "718f8ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                              -   \n",
       "1     2                 Tamil Nadu                      1,845,853   \n",
       "2     3              Uttar Pradesh                      1,687,818   \n",
       "3     4                    Gujarat                              -   \n",
       "4     5                  Karnataka                      1,631,977   \n",
       "5     6                West Bengal                      1,253,832   \n",
       "6     7                  Rajasthan                      1,020,989   \n",
       "7     8             Andhra Pradesh                        972,782   \n",
       "8     9                  Telangana                        969,604   \n",
       "9    10             Madhya Pradesh                        906,672   \n",
       "10   11                     Kerala                              -   \n",
       "11   12                      Delhi                        856,112   \n",
       "12   13                    Haryana                        831,610   \n",
       "13   14                      Bihar                        611,804   \n",
       "14   15                     Punjab                        574,760   \n",
       "15   16                     Odisha                        521,275   \n",
       "16   17                      Assam                              -   \n",
       "17   18               Chhattisgarh                        329,180   \n",
       "18   19                  Jharkhand                        328,598   \n",
       "19   20                Uttarakhand                              -   \n",
       "20   21            Jammu & Kashmir                              -   \n",
       "21   22           Himachal Pradesh                        165,472   \n",
       "22   23                        Goa                         80,449   \n",
       "23   24                    Tripura                         55,984   \n",
       "24   25                 Chandigarh                              -   \n",
       "25   26                 Puducherry                         38,253   \n",
       "26   27                  Meghalaya                         36,572   \n",
       "27   28                     Sikkim                         32,496   \n",
       "28   29                    Manipur                         31,790   \n",
       "29   30                   Nagaland                              -   \n",
       "30   31          Arunachal Pradesh                              -   \n",
       "31   32                    Mizoram                         26,503   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices  Share(18-19)  GDP($ billion)  \n",
       "0                       2,632,792        13.94%         399.921  \n",
       "1                       1,630,208         8.63%         247.629  \n",
       "2                       1,584,764         8.39%         240.726  \n",
       "3                       1,502,899         7.96%         228.290  \n",
       "4                       1,493,127         7.91%         226.806  \n",
       "5                       1,089,898         5.77%         165.556  \n",
       "6                         942,586         4.99%         143.179  \n",
       "7                         862,957         4.57%         131.083  \n",
       "8                         861,031         4.56%         130.791  \n",
       "9                         809,592         4.29%         122.977  \n",
       "10                        781,653         4.14%         118.733  \n",
       "11                        774,870         4.10%         117.703  \n",
       "12                        734,163         3.89%         111.519  \n",
       "13                        530,363         2.81%          80.562  \n",
       "14                        526,376         2.79%          79.957  \n",
       "15                        487,805         2.58%          74.098  \n",
       "16                        315,881         1.67%          47.982  \n",
       "17                        304,063         1.61%          46.187  \n",
       "18                        297,204         1.57%          45.145  \n",
       "19                        245,895         1.30%          37.351  \n",
       "20                        155,956         0.83%          23.690  \n",
       "21                        153,845         0.81%          23.369  \n",
       "22                         73,170         0.39%          11.115  \n",
       "23                         49,845         0.26%           7.571  \n",
       "24                         42,114         0.22%           6.397  \n",
       "25                         34,433         0.18%           5.230  \n",
       "26                         33,481         0.18%           5.086  \n",
       "27                         28,723         0.15%           4.363  \n",
       "28                         27,870         0.15%           4.233  \n",
       "29                         27,283         0.14%           4.144  \n",
       "30                         24,603         0.13%           3.737  \n",
       "31                         22,287         0.12%           3.385  \n",
       "32                              -             -               -  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank[0:33] , ' State':State[:33] , 'GSDP(18-19)- at current prices':GSDP_1[:33] , 'GSDP(19-20)- at current prices':GSDP_2[:33], ' Share(18-19)':Share[:33], ' GDP($ billion)':GDP[:33]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff695f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505a7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.4. Scrape the details of trending repositories on Github.com.\n",
    "#Url = https://github.com/\n",
    "#You have to find the following details:\n",
    "#A) Repository title\n",
    "#B) Repository description\n",
    "#C) Contributors count\n",
    "#D) Language used\n",
    "#Note: - From the home page you have to click on the trending option from Explore menu through code\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser ( Open trending repositories)\n",
    "\n",
    "driver.get('https://github.com/')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Then click the 'open source' \n",
    "Select=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "Select.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#Then click the trending option in 'open source'\n",
    "india=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "india.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7c29f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Empty list for store \n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "URL=[]\n",
    "\n",
    "#Scraping URL\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"Link\"]'):\n",
    "    URL.append(i.get_attribute('href')) #to retrive any link we use get_attribute \n",
    "    \n",
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d132976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25, 25, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in URL:       #iterating each and every URL to fetch full details ( loop for every details in the list)\n",
    "    driver.get(i)   # taing each URL one by one as an input\n",
    "    \n",
    "    \n",
    "     #Scraping Repository_title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH,'//div[@class=\"flex-auto min-width-0 width-fit mr-3\"]')\n",
    "        Repository_title.append(title.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append('-')\n",
    "\n",
    "\n",
    "\n",
    "     #Scraping Repository_description\n",
    "    try:\n",
    "        description = driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        Repository_description.append(description.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append('-')\n",
    "        \n",
    "\n",
    "     #Scraping Contributors_count\n",
    "    try:\n",
    "        contributors = driver.find_element(By.XPATH,'//span[@class=\"Counter ml-1\"]')\n",
    "        Contributors_count.append(contributors.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append('-')\n",
    "        \n",
    "   \n",
    "    \n",
    "    \n",
    "    #Scraping Language_used\n",
    "    try:\n",
    "        language = driver.find_element(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        Language_used.append(language.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Language_used.append('-')\n",
    "    \n",
    "    \n",
    "\n",
    "len(Repository_title),len(Repository_description),len(Contributors_count),len(Language_used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9afae997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteByteGoHq\\n/\\nsystem-design-101\\nPublic</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenBMB\\n/\\nXAgent\\nPublic</td>\n",
       "      <td>An Autonomous LLM Agent for Complex Task Solving</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ionic-team\\n/\\nionic-framework\\nPublic</td>\n",
       "      <td>A powerful cross-platform UI toolkit for build...</td>\n",
       "      <td>468</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cpacker\\n/\\nMemGPT\\nPublic</td>\n",
       "      <td>Teaching LLMs memory management for unbounded ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex313031\\n/\\nthorium\\nPublic</td>\n",
       "      <td>Chromium fork named after radioactive element ...</td>\n",
       "      <td></td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cloudcommunity\\n/\\nFree-Certifications\\nPublic</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>53</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DarkFlippers\\n/\\nunleashed-firmware\\nPublic</td>\n",
       "      <td>Flipper Zero Unleashed Firmware</td>\n",
       "      <td>292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheRealJoelmatic\\n/\\nRemoveAdblockThing\\nPublic</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>refinedev\\n/\\nrefine\\nPublic</td>\n",
       "      <td>Build your React-based CRUD applications, with...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PWhiddy\\n/\\nPokemonRedExperiments\\nPublic</td>\n",
       "      <td>Playing Pokemon Red with Reinforcement Learning</td>\n",
       "      <td></td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex313031\\n/\\nThorium-Win\\nPublic</td>\n",
       "      <td>Chromium fork for Windows named after radioact...</td>\n",
       "      <td></td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>imteekay\\n/\\nprogramming-language-research\\nPu...</td>\n",
       "      <td>Programming Language Research, Applied PLT &amp; C...</td>\n",
       "      <td>4</td>\n",
       "      <td>Clojure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>devfullcycle\\n/\\nimersao15\\nPublic</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>langchain-ai\\n/\\nlangchain\\nPublic</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Azure-Samples\\n/\\nazure-search-openai-demo\\nPu...</td>\n",
       "      <td>A sample app for the Retrieval-Augmented Gener...</td>\n",
       "      <td>49</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>felipemotarocha\\n/\\nfullstackweek-store\\nPublic</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Azure\\n/\\nazure-sdk-for-java\\nPublic</td>\n",
       "      <td>This repository is for active development of t...</td>\n",
       "      <td>593</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trufflesecurity\\n/\\ntrufflehog\\nPublic</td>\n",
       "      <td>Find and verify credentials</td>\n",
       "      <td>1</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kong\\n/\\nkong\\nPublic</td>\n",
       "      <td>🦍 The Cloud-Native API Gateway</td>\n",
       "      <td></td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nextauthjs\\n/\\nnext-auth\\nPublic</td>\n",
       "      <td>Authentication for the Web.</td>\n",
       "      <td>595</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3-oss\\n/\\ncreate-t3-app\\nPublic</td>\n",
       "      <td>The best way to start a full-stack, typesafe N...</td>\n",
       "      <td>265</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mkkellogg\\n/\\nGaussianSplats3D\\nPublic</td>\n",
       "      <td>Three.js-based implementation of the 3D Gaussi...</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Orange-Cyberdefense\\n/\\nGOAD\\nPublic</td>\n",
       "      <td>game of active directory</td>\n",
       "      <td></td>\n",
       "      <td>PowerShell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cloudflare\\n/\\nworkers-sdk\\nPublic</td>\n",
       "      <td>⛅️ Home to Wrangler, the CLI for Cloudflare Wo...</td>\n",
       "      <td>126</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nodejs\\n/\\nnode\\nPublic</td>\n",
       "      <td>Node.js JavaScript runtime ✨🐢🚀✨</td>\n",
       "      <td>3,307</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0          ByteByteGoHq\\n/\\nsystem-design-101\\nPublic   \n",
       "1                          OpenBMB\\n/\\nXAgent\\nPublic   \n",
       "2              ionic-team\\n/\\nionic-framework\\nPublic   \n",
       "3                          cpacker\\n/\\nMemGPT\\nPublic   \n",
       "4                      Alex313031\\n/\\nthorium\\nPublic   \n",
       "5      cloudcommunity\\n/\\nFree-Certifications\\nPublic   \n",
       "6         DarkFlippers\\n/\\nunleashed-firmware\\nPublic   \n",
       "7     TheRealJoelmatic\\n/\\nRemoveAdblockThing\\nPublic   \n",
       "8                        refinedev\\n/\\nrefine\\nPublic   \n",
       "9           PWhiddy\\n/\\nPokemonRedExperiments\\nPublic   \n",
       "10                 Alex313031\\n/\\nThorium-Win\\nPublic   \n",
       "11  imteekay\\n/\\nprogramming-language-research\\nPu...   \n",
       "12                 devfullcycle\\n/\\nimersao15\\nPublic   \n",
       "13                 langchain-ai\\n/\\nlangchain\\nPublic   \n",
       "14  Azure-Samples\\n/\\nazure-search-openai-demo\\nPu...   \n",
       "15    felipemotarocha\\n/\\nfullstackweek-store\\nPublic   \n",
       "16               Azure\\n/\\nazure-sdk-for-java\\nPublic   \n",
       "17             trufflesecurity\\n/\\ntrufflehog\\nPublic   \n",
       "18                              Kong\\n/\\nkong\\nPublic   \n",
       "19                   nextauthjs\\n/\\nnext-auth\\nPublic   \n",
       "20                   t3-oss\\n/\\ncreate-t3-app\\nPublic   \n",
       "21             mkkellogg\\n/\\nGaussianSplats3D\\nPublic   \n",
       "22               Orange-Cyberdefense\\n/\\nGOAD\\nPublic   \n",
       "23                 cloudflare\\n/\\nworkers-sdk\\nPublic   \n",
       "24                            nodejs\\n/\\nnode\\nPublic   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   Explain complex systems using visuals and simp...                      \n",
       "1    An Autonomous LLM Agent for Complex Task Solving                      \n",
       "2   A powerful cross-platform UI toolkit for build...                468   \n",
       "3   Teaching LLMs memory management for unbounded ...                  9   \n",
       "4   Chromium fork named after radioactive element ...                      \n",
       "5    A curated list of free courses & certifications.                 53   \n",
       "6                     Flipper Zero Unleashed Firmware                292   \n",
       "7   Removes The \"Ad blocker are not allowed on You...                      \n",
       "8   Build your React-based CRUD applications, with...                      \n",
       "9     Playing Pokemon Red with Reinforcement Learning                      \n",
       "10  Chromium fork for Windows named after radioact...                      \n",
       "11  Programming Language Research, Applied PLT & C...                  4   \n",
       "12                                                  -                      \n",
       "13  ⚡ Building applications with LLMs through comp...                      \n",
       "14  A sample app for the Retrieval-Augmented Gener...                 49   \n",
       "15                                                  -                      \n",
       "16  This repository is for active development of t...                593   \n",
       "17                        Find and verify credentials                  1   \n",
       "18                     🦍 The Cloud-Native API Gateway                      \n",
       "19                        Authentication for the Web.                595   \n",
       "20  The best way to start a full-stack, typesafe N...                265   \n",
       "21  Three.js-based implementation of the 3D Gaussi...                      \n",
       "22                           game of active directory                      \n",
       "23  ⛅️ Home to Wrangler, the CLI for Cloudflare Wo...                126   \n",
       "24                    Node.js JavaScript runtime ✨🐢🚀✨              3,307   \n",
       "\n",
       "       Language used  \n",
       "0                  -  \n",
       "1         TypeScript  \n",
       "2         TypeScript  \n",
       "3             Python  \n",
       "4                C++  \n",
       "5                  -  \n",
       "6                  C  \n",
       "7         JavaScript  \n",
       "8         TypeScript  \n",
       "9   Jupyter Notebook  \n",
       "10         Batchfile  \n",
       "11           Clojure  \n",
       "12                Go  \n",
       "13            Python  \n",
       "14            Python  \n",
       "15        TypeScript  \n",
       "16              Java  \n",
       "17                Go  \n",
       "18               Lua  \n",
       "19        TypeScript  \n",
       "20        TypeScript  \n",
       "21        JavaScript  \n",
       "22        PowerShell  \n",
       "23        TypeScript  \n",
       "24        JavaScript  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Repository title':Repository_title , 'Repository description':Repository_description , 'Contributors count':Contributors_count , 'Language used':Language_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc6633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20ea7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "#following details:\n",
    "#A) Song name\n",
    "#B) Artist name\n",
    "#C) Last week rank\n",
    "#D) Peak rank\n",
    "#E) Weeks on board\n",
    "#Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser ( Open billiboard )\n",
    "\n",
    "driver.get('https:/www.billboard.com/')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Then click the 'CHARTS' \n",
    "Select=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "Select.click()\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#Then click the option 'billiboard Hot 100'\n",
    "billiboard=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a')\n",
    "billiboard.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a5d3e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99, 99, 99, 99)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Empty list for store \n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week=[]\n",
    "Peak_rank=[]\n",
    "Weeks_board=[]\n",
    "\n",
    "\n",
    "\n",
    "#Scraping Song_name from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    Song_name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping Artist_name from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    Artist_name.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "#Scraping Last week Rank from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]'):\n",
    "    Last_week.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "#Scraping Peak_rank from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]'):\n",
    "    Peak_rank.append(i.text)\n",
    "    \n",
    "\n",
    "    \n",
    "#Scraping Weeks on board from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]'):\n",
    "    Weeks_board.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "# Print the lengths of lists \n",
    "len(Song_name),len(Artist_name),len(Last_week),len(Peak_rank),len(Weeks_board)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b0df303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDGAF</td>\n",
       "      <td>Drake Featuring Yeat</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake Featuring 21 Savage</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slime You Out</td>\n",
       "      <td>Drake Featuring SZA</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>God Gave Me A Girl</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Y Lloro</td>\n",
       "      <td>Junior H</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Telekinesis</td>\n",
       "      <td>Travis Scott Featuring SZA &amp; Future</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Seven</td>\n",
       "      <td>Jung Kook Featuring Latto</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Stars Like Confetti</td>\n",
       "      <td>Dustin Lynch</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Song name                          Artist name Last week rank  \\\n",
       "0                 IDGAF                 Drake Featuring Yeat              -   \n",
       "1        Virginia Beach                                Drake              -   \n",
       "2    Paint The Town Red                             Doja Cat              1   \n",
       "3       Calling For You            Drake Featuring 21 Savage              -   \n",
       "4         Slime You Out                  Drake Featuring SZA             18   \n",
       "..                  ...                                  ...            ...   \n",
       "94   God Gave Me A Girl                    Russell Dickerson             90   \n",
       "95              Y Lloro                             Junior H              -   \n",
       "96          Telekinesis  Travis Scott Featuring SZA & Future             72   \n",
       "97                Seven            Jung Kook Featuring Latto             57   \n",
       "98  Stars Like Confetti                         Dustin Lynch             89   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          2              1  \n",
       "1          3              1  \n",
       "2          1             10  \n",
       "3          5              1  \n",
       "4          1              4  \n",
       "..       ...            ...  \n",
       "94        90              2  \n",
       "95        97              1  \n",
       "96        26             11  \n",
       "97         1             13  \n",
       "98        89              2  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Song name':Song_name , 'Artist name':Artist_name , 'Last week rank':Last_week , 'Peak rank':Peak_rank, 'Weeks on board':Weeks_board})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c0bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e20d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Scrape the details of Highest selling novels.\n",
    "#A) Book name\n",
    "#B) Author name\n",
    "#C) Volumes sold\n",
    "#D) Publisher\n",
    "#E) Genre\n",
    "#Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser \n",
    "\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c0d612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty lists for storing data\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "\n",
    "#Scraping Book_name from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]'):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping Author_name from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]'):\n",
    "    Author_name.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Scraping Volumes_sold from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]'):\n",
    "    Volumes_sold.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "#Scraping Publisher from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]'):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "\n",
    "\n",
    "#Scraping Genre from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]'):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "\n",
    "    \n",
    "# Print the lengths of lists \n",
    "len(Book_name),len(Author_name),len(Volumes_sold),len(Publisher),len(Genre)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f643d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Book name':Book_name , ' Author name':Author_name , 'Volumes sold':Volumes_sold , 'Publisher':Publisher, ' Genre':Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f6f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e22c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "#Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "#to find the following details:\n",
    "#A) Name\n",
    "#B) Year span\n",
    "#C) Genre\n",
    "#D) Run time\n",
    "#E) Ratings\n",
    "#F) Votes\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser \n",
    "\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0fff9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty lists for storing data\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "\n",
    "#Scraping Name from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a'):\n",
    "    Name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping Year_span from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]'):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Scraping Genre from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "#Scraping Run_time from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "\n",
    "\n",
    "#Scraping Ratings from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]'):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Votes from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//span[@name=\"nv\"]'):\n",
    "    Votes.append(i.text)    \n",
    "    \n",
    "\n",
    "    \n",
    "# Print the lengths of lists \n",
    "len(Name),len(Year_span),len(Genre),len(Run_time),len(Ratings),len(Votes)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cff6d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,213,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,283,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,050,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>270,253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time  Ratings      Votes  \n",
       "0    57 min      9.2  2,213,628  \n",
       "1    51 min      8.7  1,283,377  \n",
       "2    44 min      8.1  1,050,461  \n",
       "3    60 min      7.5    308,644  \n",
       "4    43 min      7.6    267,582  \n",
       "..      ...      ...        ...  \n",
       "95   42 min      7.5     52,961  \n",
       "96   50 min      7.8     65,033  \n",
       "97   42 min      8.1    211,945  \n",
       "98   45 min        7     44,115  \n",
       "99  572 min      8.6    270,253  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Name':Name , ' Year span':Year_span , 'Genre':Genre , 'Run_time':Run_time, ' Ratings':Ratings, 'Votes':Votes })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28709d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04cf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Details of Datasets from UCI machine learning repositories.\n",
    "#Url = https://archive.ics.uci.edu/ You\n",
    "#have to find the following details:\n",
    "#A) Dataset name\n",
    "#B) Data type\n",
    "#C) Task\n",
    "#D) Attribute type\n",
    "#E) No of instances\n",
    "#F) No of attribute G) Year\n",
    "#Note: - from the home page you have to go to the Show All Dataset page through code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException   #importing exception, since we are using dynamic page/website where the elements in page might be relocated or added or value get change \n",
    "\n",
    "driver =webdriver.Chrome()\n",
    "\n",
    "#opening the website on automated chrome browser \n",
    "\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Then click the 'View Dataset' \n",
    "Dataset=driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "Dataset.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732c0275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Empty list for store \n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_instances=[]\n",
    "No_attribute=[]\n",
    "Year=[]\n",
    "URL=[]\n",
    "\n",
    "#till all pages so that we can scrape all datas\n",
    "start= 0\n",
    "end= 65\n",
    "\n",
    "\n",
    "for page in range(start,end): #for loop for scrapping page\n",
    "    #Scraping URL\n",
    "    for i in driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]'):\n",
    "        URL.append(i.get_attribute('href')) #to retrive any link we use get_attribute \n",
    "    \n",
    "\n",
    "    next_button=driver.find_element(By.XPATH,'//button[2][@class=\"btn-primary btn-sm btn\"]') #to scrape data from next page (here we are usig 'find _elements' instead of 'find_element', so no need to write 'next_button.click()' command in next line)\n",
    "    next_button.click()\n",
    "    time.sleep(4) \n",
    "\n",
    "\n",
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf0e956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 650, 650, 650, 650, 650, 650)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in URL:       #iterating each and every URL to fetch full job details ( loop for every guitar in the list)\n",
    "    driver.get(i)   # taing each URL one by one as an input\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Scraping Dataset_name\n",
    "    try:\n",
    "        dataset = driver.find_element(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div/div')\n",
    "        Dataset_name.append(dataset.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "        \n",
    "    #Scraping Data_type\n",
    "    try:\n",
    "        Data = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[4]/p')\n",
    "        Data_type.append(Data.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping Task\n",
    "    try:\n",
    "        mission = driver.find_element(By.XPATH,'//p[@class=\"svelte-17wf9gp\"]')\n",
    "        Task.append(mission.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping Attribute_type\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[1]/p')\n",
    "        Attribute_type.append(attribute.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    \n",
    "    #Scraping No_instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[5]/p')\n",
    "        No_instances.append(instances.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        No_instances.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping No_attribute\n",
    "    try:\n",
    "        attriuteno = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[6]/p')\n",
    "        No_attribute.append(attriuteno.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        No_attribute.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Scraping Year\n",
    "    try:\n",
    "        date = driver.find_element(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div/h2')\n",
    "        Year.append(date.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "        \n",
    "        \n",
    "len(Dataset_name),len(Data_type),len(Task),len(Attribute_type),len(No_instances),len(No_attribute),len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d406f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No. of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Real</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>Donated on 6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Real</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>BAUM-2</td>\n",
       "      <td>-</td>\n",
       "      <td>A multilingual audio-visual affective face dat...</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>1047</td>\n",
       "      <td>-</td>\n",
       "      <td>Donated on 11/8/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>NSF Research Award Abstracts 1990-2003</td>\n",
       "      <td>-</td>\n",
       "      <td>This data set consists of (a) 129,000 abstract...</td>\n",
       "      <td>Text</td>\n",
       "      <td>129000</td>\n",
       "      <td>-</td>\n",
       "      <td>Donated on 11/17/2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Undocumented</td>\n",
       "      <td>-</td>\n",
       "      <td>Various datasets without documentation (feel f...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Opinosis Opinion / Review</td>\n",
       "      <td>-</td>\n",
       "      <td>This dataset contains sentences extracted from...</td>\n",
       "      <td>Text</td>\n",
       "      <td>51</td>\n",
       "      <td>-</td>\n",
       "      <td>Donated on 7/5/2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>DGP2 - The Second Data Generation Program</td>\n",
       "      <td>Real</td>\n",
       "      <td>Generates application domains based on specifi...</td>\n",
       "      <td>Data-Generator</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Dataset name                   Data type  \\\n",
       "0                                         Iris                        Real   \n",
       "1                                Heart Disease  Categorical, Integer, Real   \n",
       "2                                        Adult        Categorical, Integer   \n",
       "3                                         Wine               Integer, Real   \n",
       "4         Breast Cancer Wisconsin (Diagnostic)                        Real   \n",
       "..                                         ...                         ...   \n",
       "645                                     BAUM-2                           -   \n",
       "646     NSF Research Award Abstracts 1990-2003                           -   \n",
       "647                               Undocumented                           -   \n",
       "648                  Opinosis Opinion / Review                           -   \n",
       "649  DGP2 - The Second Data Generation Program                        Real   \n",
       "\n",
       "                                                  Task  Attribute type  \\\n",
       "0    A small classic dataset from Fisher, 1936. One...         Tabular   \n",
       "1    4 databases: Cleveland, Hungary, Switzerland, ...    Multivariate   \n",
       "2    Predict whether income exceeds $50K/yr based o...    Multivariate   \n",
       "3    Using chemical analysis to determine the origi...         Tabular   \n",
       "4         Diagnostic Wisconsin Breast Cancer Database.    Multivariate   \n",
       "..                                                 ...             ...   \n",
       "645  A multilingual audio-visual affective face dat...     Time-Series   \n",
       "646  This data set consists of (a) 129,000 abstract...            Text   \n",
       "647  Various datasets without documentation (feel f...               -   \n",
       "648  This dataset contains sentences extracted from...            Text   \n",
       "649  Generates application domains based on specifi...  Data-Generator   \n",
       "\n",
       "    No. of instances No of attribute                   Year  \n",
       "0                150               4   Donated on 6/30/1988  \n",
       "1                303              13   Donated on 6/30/1988  \n",
       "2              48842              14   Donated on 4/30/1996  \n",
       "3                178              13   Donated on 6/30/1991  \n",
       "4                569              30  Donated on 10/31/1995  \n",
       "..               ...             ...                    ...  \n",
       "645             1047               -   Donated on 11/8/2018  \n",
       "646           129000               -  Donated on 11/17/2003  \n",
       "647                -               -                      -  \n",
       "648               51               -    Donated on 7/5/2010  \n",
       "649                -               -                      -  \n",
       "\n",
       "[650 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't know how to scrape data from the last page, last 7 datas from the last page.\n",
    "#Finally create a dataframe of the scraped data.\n",
    "df=pd.DataFrame({'Dataset name':Dataset_name , ' Data type':Data_type , 'Task':Task , 'Attribute type':Attribute_type, 'No. of instances':No_instances, 'No of attribute':No_attribute, 'Year':Year })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348c55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13d6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60d4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
